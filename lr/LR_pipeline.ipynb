{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2bdb346-844e-4aad-b24e-77f4995770b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from custom_tf_idf_transformer_class import CustomClassTfidfTransformer\n",
    "from write_csv_and_push_data import cleaning_strings\n",
    "\n",
    "from annoy import AnnoyIndex\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4234b76-ad0c-4b19-ab69-658035348ccf",
   "metadata": {},
   "source": [
    "GET TABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f76eafa-947f-46be-9fed-05be78ed6bce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from cdiscount import config\n",
    "from cdiscount import snowflake\n",
    "\n",
    "secrets = config.load_secrets('secrets.yml', key='snowflake')\n",
    "with snowflake.get_snowflake_connection(**secrets) as con:\n",
    "    julien_product_seller_df = pd.read_csv(\"/home/jupyter/20231123_stage_vincent_product_seller_edges.csv\", sep=\",\", engine=\"python\")\n",
    "    julien_products_df = pd.read_csv(\"/home/jupyter/20231123_stage_vincent_products.csv\", sep=\",\", engine=\"python\")\n",
    "    lr_df = snowflake.query_snowflake_to_df(\n",
    "    \"\"\"\n",
    "   WITH table_julien AS (\n",
    "    WITH\n",
    "        CATEGORY_LEVEL4_PERIMETER AS (\n",
    "            SELECT DISTINCT PRODUCT_CATEGORY_LEVEL4_ID AS PRODUCT_CATEGORY_LEVEL4_ID\n",
    "            FROM QUALISCORE_LAB.LAB_STAGE_VINCENT_CANAPES_WITH_PROPERTIES\n",
    "        ),\n",
    "        CATEGORY_LEVEL3_PERIMETER AS (\n",
    "            SELECT DISTINCT\n",
    "                C.PRODUCT_CATEGORY_LEVEL3_ID,\n",
    "                C.PRODUCT_CATEGORY_LEVEL4_ID\n",
    "            FROM CATEGORY_LEVEL4_PERIMETER AS P\n",
    "            INNER JOIN REFERENTIEL_SMT.SMT_RFL_DIM_PRODUCT_CATEGORY AS C\n",
    "                ON P.PRODUCT_CATEGORY_LEVEL4_ID = C.PRODUCT_CATEGORY_LEVEL4_ID\n",
    "                AND PRODUCT_CATEGORY_DEPTH = 4\n",
    "        ),\n",
    "        CATEGORY_LEVEL3_PATH_PERIMETER AS (\n",
    "            SELECT\n",
    "                P.PRODUCT_CATEGORY_LEVEL3_ID,\n",
    "                P.PRODUCT_CATEGORY_LEVEL4_ID,\n",
    "                C.PRODUCT_CATEGORY_CODE_PATH\n",
    "            FROM CATEGORY_LEVEL3_PERIMETER AS P\n",
    "            INNER JOIN REFERENTIEL_SMT.SMT_RFL_DIM_PRODUCT_CATEGORY AS C\n",
    "                ON P.PRODUCT_CATEGORY_LEVEL3_ID = C.PRODUCT_CATEGORY_LEVEL3_ID\n",
    "                AND PRODUCT_CATEGORY_DEPTH = 3\n",
    "        ),\n",
    "        TRAFFIC AS (\n",
    "            SELECT\n",
    "                SEARCH_ID,\n",
    "                SUM(VIEW_COUNT::FLOAT) AS VIEW_COUNT,\n",
    "                SUM(CLICK_COUNT) AS CLICK_COUNT,\n",
    "                SUM(TURNOVER) AS TURNOVER\n",
    "            FROM SEARCH_SMT.SMT_SCH_AGG_SEARCH_LIST_TRACKING_KPI\n",
    "            WHERE SNAPSHOT_DATE BETWEEN DATE('2023-11-24') - 119 AND DATE('2023-11-24')\n",
    "                AND SITE_ID = 100\n",
    "                AND AB_TESTING_GROUP = 'A'\n",
    "                AND SEARCH_ID <> ''\n",
    "                AND SEARCH_ID IS NOT NULL\n",
    "            GROUP BY SEARCH_ID, SNAPSHOT_DATE\n",
    "        ),\n",
    "        CUMULATIVE_TRAFFIC AS (\n",
    "            SELECT\n",
    "                SEARCH_ID,\n",
    "                (\n",
    "                    SUM(VIEW_COUNT)\n",
    "                    OVER(\n",
    "                        ORDER BY VIEW_COUNT DESC, TURNOVER DESC, CLICK_COUNT DESC\n",
    "                        ROWS UNBOUNDED PRECEDING\n",
    "                    )\n",
    "                ) / (\n",
    "                    SUM(VIEW_COUNT)\n",
    "                    OVER()\n",
    "                ) AS CUM_QP_TRAFFIC\n",
    "            FROM TRAFFIC\n",
    "        ),\n",
    "        TRAFFIC_BINS AS (\n",
    "            SELECT\n",
    "                SEARCH_ID,\n",
    "                FLOOR(\n",
    "                    IFF(\n",
    "                        CUM_QP_TRAFFIC = 1,\n",
    "                        CUM_QP_TRAFFIC - 1e-5,\n",
    "                        CUM_QP_TRAFFIC\n",
    "                    ) * 10\n",
    "                ) AS SEARCH_ID_GROUP\n",
    "            FROM CUMULATIVE_TRAFFIC\n",
    "        )\n",
    "    SELECT\n",
    "        LR.SEARCH_ID,\n",
    "        P.PRODUCT_CATEGORY_CODE_PATH\n",
    "    FROM CATEGORY_LEVEL3_PATH_PERIMETER AS P\n",
    "    INNER JOIN SEARCH_SMT.SMT_SCH_DIM_SEARCH_LIST_CATEGORY_FILTER AS LR\n",
    "        ON P.PRODUCT_CATEGORY_CODE_PATH = LR.CATEGORY_FILTER_PATH_CODE\n",
    "        AND LR.SNAPSHOT_DATE = '2023-11-24'\n",
    "        AND LR.SITE_ID = 100\n",
    "        AND LR.AB_TESTING_SVC_COOKIE_GROUP = 'A'\n",
    "    INNER JOIN TRAFFIC_BINS AS T\n",
    "        ON LR.SEARCH_ID = T.SEARCH_ID\n",
    "    WHERE SEARCH_ID_GROUP = 9),\n",
    "    FULL_DATA AS (\n",
    "    SELECT     rerank.search_id,\n",
    "               ARRAY_AGG(DISTINCT rerank.product_id) AS product_id_list,\n",
    "               page_number\n",
    "            FROM SEARCH_SMT.SMT_SCH_AGG_SEARCH_LIST_PRODUCT_VIEW AS rerank\n",
    "            JOIN table_julien\n",
    "                ON table_julien.search_id = rerank.search_id\n",
    "                WHERE rerank.site_id = 100\n",
    "                AND rerank.snapshot_date >= DATE('2023-11-24')\n",
    "            GROUP BY (rerank.search_id, page_number))\n",
    "    SELECT * FROM full_data WHERE ARRAY_SIZE(product_id_list) >=1;\n",
    "    \"\"\", con=con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bdb39b6-7a14-4aea-82ec-9ea660ce61ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr_df[\"product_id_list\"] = lr_df.product_id_list.apply(eval)\n",
    "exploded_lr_df = lr_df.explode(\"product_id_list\").reset_index()\n",
    "exploded_lr_df.drop_duplicates(subset=[\"product_id_list\"], inplace=True)\n",
    "full_df = julien_products_df.merge(exploded_lr_df, left_on=\"product_id\", right_on=\"product_id_list\")\n",
    "full_df.rename(columns={'fp_product_name':'product_name', 'product_long_description':'description'}, inplace=True)\n",
    "full_df.reset_index()\n",
    "full_df.description.fillna(\"\", inplace=True)\n",
    "full_df.description = cleaning_strings(full_df.description)\n",
    "full_df.product_name = cleaning_strings(full_df.product_name)\n",
    "full_df.drop(columns=['product_id_list',\n",
    "                      'product_short_description',\n",
    "                      'product_properties',\n",
    "                      'preprocessed_product_properties',\n",
    "                      'product_marketing_description',\n",
    "                      'total_token_fp_product_name',\n",
    "                      'total_token_product_long_description',\n",
    "                      'total_token_fp_content',\n",
    "                      #'community_id'\n",
    "                     ], inplace=True)\n",
    "#exploded_lr_df['community_id'] = full_df.community_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a0feb2-6a29-4c94-a27d-b523e7aefc23",
   "metadata": {},
   "source": [
    "ANNOY-ING NEIGHBORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6581a261-4e05-494e-97f5-44ae28cf0e18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def id2product_id(index):\n",
    "    return full_df.iloc[index].product_id\n",
    "\n",
    "def get_neighbors(u, i, k):\n",
    "    neighbors, distances = u.get_nns_by_item(i=i, n=k+1, include_distances=True)\n",
    "    return (\n",
    "      pd.DataFrame({\n",
    "          'id': i,\n",
    "          'neighbor_id': neighbors,\n",
    "          'distance': distances\n",
    "      })\n",
    "      .loc[lambda x: x.neighbor_id.ne(i)]\n",
    "      .assign(rank=[j for j in range(1, k+1)])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb32c7db-b080-41d5-a508-b298c0acb199",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = full_df[\"index\"]\n",
    "vec_dim = 1536\n",
    "original_annoy_index = AnnoyIndex(vec_dim, 'dot')\n",
    "original_annoy_index.load('/home/jupyter/20231123_stage_vincent_products_fp_content.ann')\n",
    "u = AnnoyIndex(vec_dim, 'dot')\n",
    "new_idx = 0\n",
    "for i in tqdm(index_list, total=len(index_list)):\n",
    "    vector = original_annoy_index.get_item_vector(i)\n",
    "    u.add_item(new_idx, vector)\n",
    "    new_idx += 1\n",
    "u.build(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5c360c-feb4-4b9d-952d-6964d321113e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "saving_csv=True\n",
    "all_neighbors = []\n",
    "for i in tqdm(range(0, u.get_n_items())):\n",
    "    all_neighbors.append(get_neighbors(u=u, i=i, k=10))\n",
    "all_neighbors = pd.concat(all_neighbors)\n",
    "all_neighbors['id'] = all_neighbors['id'].apply(id2product_id)\n",
    "all_neighbors['neighbor_id'] = all_neighbors['neighbor_id'].apply(id2product_id)\n",
    "scaler = MinMaxScaler()\n",
    "all_neighbors['distance'] = scaler.fit_transform(all_neighbors[['distance']])\n",
    "if saving_csv:\n",
    "    all_neighbors.to_csv(\"csv_files/lr_product_product.csv\", index=False, sep='\\u0001')\n",
    "    \n",
    "# all_neighbors[[\"id\", \"neighbor_id\"]].apply(lambda x: \" | \".join(np.sort(x)), axis=1).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2c6b5c-2d69-4cbd-9188-afc50f2fc894",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "product_id = 'EJL1694120625827'\n",
    "\n",
    "print(full_df[full_df.product_id == product_id].product_name.item())\n",
    "for neighbor in all_neighbors[all_neighbors.id == product_id].neighbor_id.tolist():\n",
    "    print(\"    \", full_df[full_df.product_id == neighbor].product_name.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1942a33d-b9b3-4fe4-b386-e9fb63ac8ac4",
   "metadata": {},
   "source": [
    "PUSH TO NEO4J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fd45b4-18dc-4ae4-ac6b-955d1db02254",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase, basic_auth\n",
    "username = \"neo4j\"\n",
    "password = \"zDje683kEKpo23\"\n",
    "driver = GraphDatabase.driver(uri=\"bolt://a08datasc002.cdbdx.biz:7687\", auth=(username, password))\n",
    "\n",
    "cleaning_all = '''\n",
    "MATCH (n)\n",
    "DETACH DELETE n\n",
    "'''\n",
    "products_idx = '''\n",
    "CREATE INDEX products_constraint IF NOT EXISTS FOR (n:Product) ON n.product_id;\n",
    "'''\n",
    "# product_property_value,product_id,product_category_level4_id,product_category_level4_name,product_long_description\n",
    "create_products_nodes = '''\n",
    "LOAD CSV WITH HEADERS FROM 'file:///var/lib/neo4j/import/lr_products.csv' AS product_line FIELDTERMINATOR ','\n",
    "// Create products\n",
    "MERGE (p:Product\n",
    "            {product_id: product_line.product_id,\n",
    "             product_name: COALESCE(product_line.fp_product_name, \"empty\"),\n",
    "             description: COALESCE(product_line.product_long_description, \"empty\")\n",
    "             })\n",
    "'''\n",
    "product_product_relationship = '''\n",
    "// Create a relationship between the products\n",
    "CALL apoc.periodic.iterate(\n",
    "  '\n",
    "  LOAD CSV WITH HEADERS FROM \"file:///var/lib/neo4j/import/lr_product_product.csv\" AS line FIELDTERMINATOR \"\\u0001\"\n",
    "  RETURN line\n",
    "  ',\n",
    "  '\n",
    "  MATCH (p:Product {product_id: line.id})\n",
    "  MATCH (neighbor:Product {product_id: line.neighbor_id})\n",
    "  MERGE (p)-[:Neighbors]->(neighbor)\n",
    "  MERGE (neighbor)-[:Neighbors]->(p)\n",
    "  ',\n",
    "  {batchSize: 5000, iterateList: true}\n",
    ")\n",
    "'''\n",
    "\n",
    "product_product_relationship_weighted = '''\n",
    "// Create a weighted relationship between the products\n",
    "CALL apoc.periodic.iterate(\n",
    "  '\n",
    "  LOAD CSV WITH HEADERS FROM \"file:///var/lib/neo4j/import/lr_product_product.csv\" AS line FIELDTERMINATOR \"\\u0001\"\n",
    "  RETURN line\n",
    "  ',\n",
    "  '\n",
    "  MATCH (p:Product {product_id: line.id})\n",
    "  MATCH (neighbor:Product {product_id: line.neighbor_id})\n",
    "  MERGE (p)-[r:Neighbors {weight: toFloat(line.distance)}]->(neighbor)\n",
    "  MERGE (neighbor)-[:Neighbors {weight: toFloat(line.distance)}]->(p)\n",
    "  ',\n",
    "  {batchSize: 5000, iterateList: true}\n",
    ")\n",
    "'''\n",
    "\n",
    "cleaning_before_pushing=True\n",
    "weighted_relationship=True\n",
    "\n",
    "with driver.session(database=\"neo4j\") as session:\n",
    "    if cleaning_before_pushing:\n",
    "        session.execute_write(\n",
    "            lambda tx: tx.run(cleaning_all).data())\n",
    "        print(\"Cleaning done\")\n",
    "    session.execute_write(\n",
    "        lambda tx: tx.run(products_idx).data())\n",
    "    print(\"Indexes done\")\n",
    "    session.execute_write(\n",
    "        lambda tx: tx.run(create_products_nodes).data())\n",
    "    print(\"Product nodes added\")\n",
    "    if weighted_relationship:\n",
    "        session.execute_write(\n",
    "            lambda tx: tx.run(product_product_relationship_weighted).data())\n",
    "    else:\n",
    "        session.execute_write(\n",
    "            lambda tx: tx.run(product_product_relationship).data())\n",
    "    print(\"product_product relationships added\")\n",
    "driver.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8477f27f-9e34-4a3f-83e7-0ba5eda25b3d",
   "metadata": {
    "tags": []
   },
   "source": [
    "ANALYSE DE COMMUNAUTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95705b5-2fb9-4d17-b53d-e0a199eb2ab6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import normalize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def extract_vocabulary(documents, stop_words, min_len: int = 3, min_df: int = 2):\n",
    "    vocabulary = ' '.join(documents)\n",
    "    vocabulary = [w for w in vocabulary.split() if w not in stop_words]\n",
    "    vocabulary = Counter(vocabulary)\n",
    "    for k, v in vocabulary.most_common():\n",
    "        if v < min_df or len(k) < min_len:\n",
    "            del vocabulary[k]\n",
    "    return [k for k, _ in vocabulary.most_common()]\n",
    "\n",
    "def merge_columns(row):\n",
    "    return f\"{' '.join(row['product_name_list'])} {row['description']}\"\n",
    "\n",
    "def get_top_words(response, threshold, feature_array):\n",
    "    #response_normalized = normalize(response, axis=1, norm='l2')\n",
    "    response_normalized = custom_norm(response.toarray())\n",
    "    response_normalized = response_normalized.reshape(-1)\n",
    "    sorted_nzs = np.argsort(response_normalized.data)[::-1]\n",
    "    feature_array = feature_array[sorted_nzs]\n",
    "    response_normalized = response_normalized[sorted_nzs]\n",
    "    response_normalized = response_normalized > threshold\n",
    "    res = feature_array[response_normalized]\n",
    "    return np.apply_along_axis(' | '.join, 0, res)\n",
    "\n",
    "def custom_norm(x):\n",
    "    norm = x.sum(axis=1)\n",
    "    return x / norm\n",
    "\n",
    "# TF-IDF METHOD\n",
    "def add_tf_idf_words(document_list, stopwords, threshold):\n",
    "    vectorizer = CountVectorizer(vocabulary=extract_vocabulary(documents=document_list, stop_words=stopwords))\n",
    "    vector = vectorizer.transform(document_list)\n",
    "    v = CustomClassTfidfTransformer(use_idf=True)\n",
    "    x = v.fit_transform(vector)\n",
    "    features = np.array(vectorizer.get_feature_names_out())\n",
    "    return [get_top_words(response=item, threshold=threshold, feature_array=features) for item in x]\n",
    "\n",
    "# COUNT VECTORIZER METHOD\n",
    "def add_count_vectorizer_words(document_list, stopwords, threshold):\n",
    "    vectorizer = CountVectorizer(vocabulary=extract_vocabulary(documents=document_list, stop_words=stopwords))\n",
    "    vector = vectorizer.transform(document_list)\n",
    "    features = np.array(vectorizer.get_feature_names_out())\n",
    "    return [get_top_words(response=item, threshold=threshold, feature_array=features) for item in vector]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54568873-b209-4fe4-a9d2-3f922837a08b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_df.drop(columns=[\"community_id_x\", \"community_id_y\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bcc7d5-a49b-4ae9-9534-e048e72ef228",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating communities_df\n",
    "\n",
    "stop_words = [\"sous\", \"sur\", \"en\", \"a\", \"d\", \"l\", \"de\", \"du\", \"des\", \"le\", \"la\", \"les\", \"un\", \"une\", \"mais\", \"ou\", \"et\", \"donc\", \"or\", \"ni\", \"car\", \"ce\", \"se\", \"ces\", \"ses\", \"ne\", \"pas\", \"tout\", \"tous\", \"toute\", \"toutes\"]\n",
    "stop_words += [\"je\", \"tu\", \"il\", \"elle\", \"nous\", \"vous\", \"ils\", \"elles\"]\n",
    "stop_words += nltk.corpus.stopwords.words('french')\n",
    "\n",
    "product_community_df = pd.read_csv(\"csv_files/communities_analysis/lr_communities_products.csv\", sep=\",\", engine=\"python\")\n",
    "full_df = full_df.merge(product_community_df, on='product_id') # Adding the column 'community_id' to full_df\n",
    "communities_df = full_df.groupby('community_id')['description'].apply(lambda x: \" | \".join(x)).reset_index()\n",
    "communities_df.set_index(\"community_id\", inplace=True)\n",
    "\n",
    "# Community size\n",
    "count = full_df.groupby('community_id').product_id.count().reset_index()\n",
    "count.set_index(\"community_id\", inplace=True)\n",
    "communities_df[\"community_size\"] = count.product_id\n",
    "len_before = len(communities_df)\n",
    "communities_df.drop(communities_df[communities_df.community_size < 2].index, inplace=True)\n",
    "len_after = len(communities_df)\n",
    "print(f\"len before is:{len_before} | len after is:{len_after}\")\n",
    "\n",
    "\n",
    "# Community Lists\n",
    "communities_df[\"product_id_list\"] = full_df.groupby(\"community_id\").product_id.apply(list)\n",
    "communities_df[\"product_name_list\"] = full_df.groupby(\"community_id\").product_name.apply(list)\n",
    "\n",
    "temp_df = exploded_lr_df.dropna().merge(full_df, left_on='product_id_list', right_on='product_id')\n",
    "temp_df.drop(columns=['search_id_x', 'search_id_y', 'community_id_x', 'index', 'brand_name', 'description', 'fp_content', 'product_id_list'], inplace=True)\n",
    "temp_df.rename(columns={'community_id_y':'community_id'}, inplace=True)\n",
    "communities_df[\"page_number_list\"] = temp_df.groupby(\"community_id\").page_number.apply(list)\n",
    "del temp_df\n",
    "\n",
    "#communities_df[\"category_name_list\"] = full_df.groupby(\"community_id\").category_name.apply(list)\n",
    "#communities_df['category_counts'] = communities_df['category_name_list'].apply(lambda x: dict(Counter(x)))\n",
    "\n",
    "\n",
    "# TF-IDF and CountVectorizer\n",
    "communities_df['document'] = communities_df.apply(merge_columns, axis=1)\n",
    "communities_df['count_vectorizer_top_words'] = add_count_vectorizer_words(document_list=communities_df.document, stopwords=stop_words, threshold=0.025)\n",
    "communities_df['tf_idf_top_words'] = add_tf_idf_words(document_list=communities_df.document, stopwords=stop_words, threshold=0.015)\n",
    "\n",
    "communities_df = communities_df.sort_values(\"community_size\", ascending=False)\n",
    "\n",
    "\n",
    "# Get the top 5 search ids\n",
    "temp_df = exploded_lr_df.dropna().groupby('community_id', as_index=True).search_id.apply(lambda x: x.value_counts(normalize=True).head(5)).reset_index()\n",
    "temp_df['search_id'] = temp_df.apply(lambda x: f\"{x['level_1']}: {x['search_id']}\", axis=1)\n",
    "temp_df.drop(columns='level_1', inplace=True)\n",
    "temp_df = temp_df.groupby('community_id').apply(lambda x: list(x.search_id)).rename(\"top_search_id_list\").reset_index()\n",
    "temp_df.head()\n",
    "communities_df = communities_df.merge(temp_df, on='community_id')\n",
    "communities_df.set_index('community_id', inplace=True)\n",
    "del temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e72e29e-1b39-4175-b895-874af789af69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "communities_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0058599-96a2-4957-b52c-6a138e60ed39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_df[full_df.search_id == 'protegecanape']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74def3f7-8ecc-479a-9aac-6c22932dc412",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# All neighbors df buffed with communities (product_id/communities/distances mapping)\n",
    "\n",
    "communities_distances_df = all_neighbors.merge(full_df, left_on='neighbor_id', right_on='product_id', how='inner')\n",
    "communities_distances_df.rename(columns={'community_id': 'neighbor_community_id'}, inplace=True)\n",
    "communities_distances_df.drop(columns=[\"product_id\"], inplace=True)\n",
    "communities_distances_df = communities_distances_df.merge(full_df, left_on='id', right_on='product_id', how='inner')\n",
    "communities_distances_df.drop(columns=[\"product_id\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a439e1-44fc-4cd8-8008-b238d9e8574c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "infos = communities_distances_df[communities_distances_df.community_id == \n",
    "            communities_distances_df.neighbor_community_id].groupby('community_id').agg(\n",
    "                dmean=(\"distance\", \"mean\"),\n",
    "                dmedian=(\"distance\", lambda x: np.quantile(x,0.5)),\n",
    "                quantile_025=(\"distance\", lambda x: np.quantile(x,0.25)),\n",
    "                quantile_095=(\"distance\", lambda x: np.quantile(x,0.95)),\n",
    "                quantile_005=(\"distance\", lambda x: np.quantile(x,0.05))\n",
    "            )\n",
    "infos['community_size'] = communities_df['community_size']\n",
    "infos.sort_values('community_size', ascending=True, inplace=True)\n",
    "infos['len_edges'] = communities_distances_df.loc[communities_distances_df.community_id == communities_distances_df.neighbor_community_id].groupby('community_id').count().id\n",
    "infos['density'] = (infos['len_edges']) / (infos['community_size'] * 10)\n",
    "\n",
    "infos.sort_values('dmean', ascending=False, inplace=True)\n",
    "print(len(infos))\n",
    "display(infos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bbefbb-91db-4407-b596-8c9901e51eca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def look4one_community(idx):\n",
    "    row = communities_df.loc[idx]\n",
    "    row_infos = infos.loc[idx]\n",
    "    print(\"\\n\\t------INFOS------\")\n",
    "    print(f\"Mean: {row_infos.dmean} | Median: {row_infos.dmedian} | Density: {row_infos.density} | Community_size: {row.community_size}\\n\",\n",
    "          f\"| Quantile 25%: {row_infos.quantile_025} | Quantile 95%: {row_infos.quantile_095} | Quantile 5%: {row_infos.quantile_005}\")\n",
    "    print(\"\\t------TOP_SEARCH_IDs------\")\n",
    "    for s_id in row.top_search_id_list:\n",
    "        print(f\"{s_id}\")\n",
    "    print(\"\\t------PRODUCTS_NAME_SAMPLE------\")\n",
    "    products_list = row.product_name_list[:25]\n",
    "    for product in products_list:\n",
    "        print(product)\n",
    "    print(end=\"\\n\\n\" + \"-\" * 150 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f997e4f-fef5-4cd4-91e3-cfb88105ffc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "look4one_community(17295)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3017dcb-2333-4c4a-a8da-8fa0c0dcc10a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp_df = full_df\n",
    "#temp_df.set_index('search_id', inplace=True)\n",
    "temp_df = temp_df.groupby('search_id').community_id.apply(lambda x: x.value_counts().head(5)).reset_index()\n",
    "#temp_df.rename(columns={'community_id':'com_id'}, inplace=True)\n",
    "temp_df.sort_values('community_id', ascending=False, inplace=True)\n",
    "display(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3269945b-d414-452f-aa33-402e372db0f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "restrained_df = temp_df[temp_df.level_1.isin(community_ids)]\n",
    "restrained_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b062205f-e252-48e2-9ea5-c7d65a141613",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(infos.columns)\n",
    "infos.sort_values('density', inplace=True, ascending=False)\n",
    "community_ids = communities_df[communities_df.community_size < 40].index\n",
    "print(f\"Number of total community is: {len(community_ids)}\")\n",
    "for community_idx in community_ids:\n",
    "    look4one_community(community_idx)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (icarusight)",
   "language": "python",
   "name": "icarusight"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc-autonumbering": false,
  "toc-showcode": true,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
