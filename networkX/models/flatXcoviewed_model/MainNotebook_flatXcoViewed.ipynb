{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ce6cc43-7731-4296-993b-b03036a750a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'query_product_df' from 'Icarusight.queries.get_queries' (/home/jupyter/Icarusight/queries/get_queries.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIcarusight\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mqueries\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mget_queries\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m query_product_df, query_co_viewed_df\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIcarusight\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mIcarusight\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIcarusight\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mIcarusight\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mflatXcoviewed_model\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mflatXcoviewed_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_flat_x_coviewed_graph\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'query_product_df' from 'Icarusight.queries.get_queries' (/home/jupyter/Icarusight/queries/get_queries.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Icarusight.queries.get_queries import query_product_df, query_co_viewed_df\n",
    "from Icarusight.Icarusight.utils import *\n",
    "from Icarusight.Icarusight.flatXcoviewed_model.flatXcoviewed_model import create_flat_x_coviewed_graph\n",
    "from Icarusight.Icarusight.clustering import get_cluster_labels, apply_clustering_algorithm\n",
    "from Icarusight.Icarusight.vectorizer.custom_tfidf_transformer_class import ClassTfidfTransformer\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from cdiscount import snowflake, config\n",
    "import os\n",
    "from numpy.linalg import norm\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a97b16d-5145-4c0c-9642-d3b9d172ffd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.chdir(\"Icarusight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d2a5e15-44b2-4ada-9210-61e5474cc7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting queries.. Done, length of co_viewed is:  886462\n",
      "Starting graph creation\n",
      "Adding nodes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 95903/95903 [01:29<00:00, 1072.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes added, adding edges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 886462/886462 [00:10<00:00, 88529.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edges added.\n",
      "Graph creation done. got 95903 nodes and 443231 edges.\n",
      "Starting clustering...\n",
      "Clustering done, removing the meaningless clusters...\n",
      "Removing done.\n"
     ]
    }
   ],
   "source": [
    "secrets = config.load_secrets('queries/secrets.yml', key='snowflake')\n",
    "con = snowflake.get_snowflake_connection(**secrets)\n",
    "print(\"Starting queries.\", end=\"\")\n",
    "product_df = query_product_df(con)\n",
    "print(\".\", end=\"\")\n",
    "co_viewed_df = query_co_viewed_df(con)\n",
    "print(\" Done, length of co_viewed is: \", len(co_viewed_df))\n",
    "\n",
    "print(\"Starting graph creation\")\n",
    "g = create_flat_x_coviewed_graph(product_df, co_viewed_df)\n",
    "print(\"Graph creation done.\", end=\" \")\n",
    "print(f\"got {len(g.nodes)} nodes and {len(g.edges)} edges.\")\n",
    "\n",
    "print(\"Starting clustering...\")\n",
    "partitions = apply_clustering_algorithm(g)\n",
    "print(\"Clustering done, removing the meaningless clusters...\")\n",
    "partitions = remove_meaningless_clusters(partitions, n=3)\n",
    "print(\"Removing done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "490222ca-f8f6-4539-8c89-40b991348c27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['product_name', 'product_category_name', 'product_category_code_path',\n",
      "       'seller_names', 'brand_name', 'product_long_description', 'cluster_id'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(product_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77ef3c9f-1339-4272-ba2c-1ffae90e4613",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    cluster_id            product_category_name   count\n",
      "0          1.0            CANAPE - SOFA - DIVAN  2703.0\n",
      "2         68.0            CANAPE - SOFA - DIVAN  1033.0\n",
      "4         87.0            CANAPE - SOFA - DIVAN  1603.0\n",
      "5        144.0                        BANQUETTE   241.0\n",
      "7        162.0            CANAPE - SOFA - DIVAN  1833.0\n",
      "9        184.0                 ENSEMBLE CANAPES   341.0\n",
      "11       226.0  CLIC-CLAC - BANQUETTE CLIC-CLAC   624.0\n",
      "12       715.0            CANAPE - SOFA - DIVAN    62.0\n",
      "13      1058.0                BZ - BANQUETTE BZ    70.0\n",
      "14      1357.0            CANAPE - SOFA - DIVAN  1807.0\n",
      "15      2264.0                       MERIDIENNE   243.0\n",
      "20      5470.0            CANAPE - SOFA - DIVAN    37.0\n",
      "30     14047.0                       MERIDIENNE    29.0\n"
     ]
    }
   ],
   "source": [
    "# Group by 'ref_category' and 'related_category' and count occurrences\n",
    "pair_counts = co_viewed_df.groupby(['ref_category_name', 'related_category_name']).size().reset_index(name='count')\n",
    "partial_product_df = product_df.where(product_df['cluster_id'].isin(partitions.values()))\n",
    "categories_count = partial_product_df.groupby(['cluster_id', 'product_category_name']).size().reset_index(name='count')\n",
    "categories_count = categories_count.where(categories_count['count'] > 10)\n",
    "# Display the counts\n",
    "print(categories_count.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03e9021a-f924-4d53-ad1a-b5910f5db594",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_results(path_to_save, cluster_infos, cluster_top_words_count, cluster_top_words_tfidf):\n",
    "    # Create a DataFrame from the dictionaries\n",
    "    cluster_labels, cluster_max_values, cluster_total_len = cluster_infos[0], cluster_infos[1], cluster_infos[2]\n",
    "    df = pd.DataFrame({\n",
    "        'cluster_id': list(cluster_labels.keys()),\n",
    "        'label': list(cluster_labels.values()),\n",
    "        'max_values': list(cluster_max_values.values()),\n",
    "        'total_len': list(cluster_total_len.values()),\n",
    "        'top_words_count_method': list(cluster_top_words_count),\n",
    "        'top_words_tfidf_method': list(cluster_top_words_tfidf)\n",
    "    })\n",
    "\n",
    "    # Write the DataFrame to a CSV file\n",
    "    df.to_csv(path_to_save, index=False)\n",
    "\n",
    "\n",
    "def remove_meaningless_clusters(input_dict, n):\n",
    "    \"\"\"\n",
    "    Reduce the number of clusters by removing the meaningless ones.\n",
    "    @param input_dict: Corresponds to the output partitions from the clustering algorithm under the form {node_id:cluster_id}\n",
    "    @type input_dict: dict[str:str]\n",
    "    @param n: Filter the clusters on their number of nodes in it. Keeps only the clusters with more than n nodes.\n",
    "    @type n: int\n",
    "    @return: Returns the input_dict without the meaningless nodes (i.e: clusters)\n",
    "    @rtype: dict[str:str]\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame({\"node_id\": input_dict.keys(), \"cluster_id\": input_dict.values()})\n",
    "    count_df = df.groupby(\"cluster_id\", as_index=False).size()\n",
    "    count_df = count_df.loc[lambda x: x[\"size\"] > n]  # Filtering by size > n\n",
    "    df = df.merge(right=count_df.drop(columns=[\"size\"]), how=\"inner\", on=\"cluster_id\")\n",
    "    return {node_id: cluster_id for node_id, cluster_id in df.itertuples(index=False)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ed17013d-ef3b-408a-ab42-264bfd5bf79d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_355782/1920937987.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  product_restrained_df['name_descr'] = product_restrained_df.product_name +  \". \" + product_restrained_df.product_long_description + \". \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster_id\n",
      "1.0        ZHI Canapé lit à 2 places Noir Tissu 738650263...\n",
      "68.0       Canapé lit élégant Canapé moderne Intérieur mo...\n",
      "87.0       Canapé convertible 3 places avec coffre de ran...\n",
      "144.0      MOO Canapé lit à 2 places Vert foncé Velours 7...\n",
      "162.0      Canapé lit à 2 places et deux oreillers Rouge ...\n",
      "184.0      Canapé 3 places et fauteuil CHESTERFIELD Simil...\n",
      "226.0      Canapé lit STAR scandinave Sofa convertible av...\n",
      "715.0      Canapé Chesterfield en forme de L Cuir synthét...\n",
      "1058.0     Banquette lit BZ matelas HR 140 cm YASMO n 2. ...\n",
      "1357.0     Canapé d angle panoramique Dante en U en velou...\n",
      "2264.0     Beliani Chaise longue rose poudré côté droit M...\n",
      "2377.0     Canapé lit à 2 places Gris clair Velours DIOCH...\n",
      "4303.0     Micadoni Home JUSTIN Canapé d angle 4 places e...\n",
      "5138.0     Canapé lit à 2 places Marron Microfibre SALALI...\n",
      "5407.0     YaJiaSheng Ensemble de canapés à 2 et à 3 plac...\n",
      "5470.0     LVL MEUBLE SOFA Canapé lit à 2 places Rose Vel...\n",
      "5505.0     ABB Canapé lit à 2 places Marron Tissu microfi...\n",
      "7682.0     Canapé angle ALMA convertible tissu rouille 4 ...\n",
      "8078.0     Micadoni Home JADE Canapé 3 places en velours ...\n",
      "8861.0     Micadoni Home JODIE Canapé d angle 4 places en...\n",
      "9998.0     Micadoni Home MILEY Canapé d angle symétrique ...\n",
      "11293.0    Canapé lit à 2 places Crème Tissu microfibre A...\n",
      "11462.0    Micadoni Home MILEY Canapé d angle gauche 6 pl...\n",
      "11726.0    8499Magnifique Canapé droit fixe 3 places Cana...\n",
      "12407.0    Pwshymi Canapé à 3 places avec repose pied Rou...\n",
      "14047.0    Micadoni Home RUBY Canapé d angle gauche 5 pla...\n",
      "18784.0    MICADONI Canapé d angle Gauche Sovite 5 places...\n",
      "27442.0    Grand canapé Sirpio XL microfibre marron kaki ...\n",
      "34442.0    Zerodis Canapé lit à 2 places avec repose pied...\n",
      "34541.0    Canapes Ensemble de canape 2 pcs Tissu Noir. E...\n",
      "41945.0    Miliboo Canapé convertible scandinave 3 places...\n",
      "Name: name_descr, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#product_df.set_index(\"product_id\", inplace=True)\n",
    "\n",
    "product_df['cluster_id'] = partitions\n",
    "product_restrained_df = product_df[~product_df['cluster_id'].isnull()]\n",
    "product_restrained_df.astype({'cluster_id': int})\n",
    "product_restrained_df['name_descr'] = product_restrained_df.product_name +  \". \" + product_restrained_df.product_long_description + \". \"\n",
    "cluster_serie = product_restrained_df.groupby(\"cluster_id\").name_descr.sum()\n",
    "print(cluster_serie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "23c06618-154a-45eb-9b87-ae39f10233a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_top_tf_idf_words(response, threshold, top_n=2):\n",
    "    #response_normalized = normalize(response, axis=1, norm='l2')\n",
    "    response_normalized = custom_norm(response)\n",
    "    response_normalized.data[response_normalized.data < threshold] = 0.0\n",
    "    response_normalized.eliminate_zeros()\n",
    "    #print(response_normalized.data)\n",
    "    sorted_nzs = np.argsort(response_normalized.data)[:-(top_n+1):-1]\n",
    "    res = feature_array[response_normalized.indices[sorted_nzs[ response_normalized.indices[sorted_nzs] > threshold]]]\n",
    "    return np.apply_along_axis(' | '.join, 0, res)\n",
    "\n",
    "def custom_norm(x):\n",
    "    norm = x.sum(axis=1)\n",
    "    return x / norm\n",
    "\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "86add6bc-6412-49dd-8671-ac46d752c903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cm | canapé | lit | siège | hauteur\n",
      "canapé | angle | cm | convertible | places\n",
      "canapé | cm | convertible | places | express\n",
      "banquette | cm | velours | pieds | tissu\n",
      "canapé | places | cm | cuir\n",
      "places | canapé | cm | ensemble | siège\n",
      "cm | canapé | lit | hauteur | dimensions\n",
      "cm | siège | cuir | hauteur | canapé\n",
      "cm | bz | banquette | matelas | couchage\n",
      "canapé | angle | convertible | tissu | places\n",
      "méridienne | cm | pieds | kg | velours\n",
      "cm | hauteur | siège | canapé | lit\n",
      "cm | poids | kg | total | meridienne\n",
      "cm | hauteur | siège | canapé | marron\n",
      "rotin | cm | canapé | coussin | couleur\n",
      "cm | hauteur | lit | canapé | siège\n",
      "cm | siège | hauteur | microfibre | lit\n",
      "canapé | angle | convertible | alma | cm\n",
      "poids | kg | volume | net | pieds\n",
      "cm | poids | kg | meridienne | total\n",
      "cm | poids | kg | accoudoir | hauteur\n",
      "cm | hauteur | siège | microfibre | canapé\n",
      "cm | poids | kg | total | largeur\n",
      "cm | canapé | siège | hauteur | places\n",
      "cm | siège | rouge | canapé | tissu\n",
      "cm | poids | kg | net | meridienne\n",
      "tissu | sovite | 278x220x74 | gauche | angle\n",
      "livraison | canapé | revêtement | continu | reins\n",
      "cm | dimensions | siège | matériau | tissu\n",
      "cm | dimensions | 70 | siège | noir\n",
      "canapé | creep | convertible | gris | places\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    " \n",
    "# COUNT VECTORIZER METHOD\n",
    "vectorizer = CountVectorizer(stop_words=nltk.corpus.stopwords.words('french'))\n",
    "vector = vectorizer.fit_transform(cluster_serie)\n",
    "top_words_per_cluster_count = [get_top_tf_idf_words(item, 0.015, 5) for item in vector]\n",
    "for top_words in top_words_per_cluster_count:\n",
    "    print(top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "04cba884-a9ca-4246-b95a-44ea46010916",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomClassTfidfTransformer(ClassTfidfTransformer):\n",
    "    def __init__(self, use_idf: bool = False, bm25_weighting: bool = False, reduce_frequent_words: bool = False):\n",
    "        super(CustomClassTfidfTransformer, self).__init__(\n",
    "            bm25_weighting=bm25_weighting,\n",
    "            reduce_frequent_words=reduce_frequent_words\n",
    "        )\n",
    "        self.use_idf = use_idf\n",
    "        \n",
    "    def transform(self, X):\n",
    "        X = normalize(X, axis=1, norm='l1', copy=False)\n",
    "\n",
    "        if self.use_idf:\n",
    "\n",
    "            if self.reduce_frequent_words:\n",
    "                X.data = np.sqrt(X.data)\n",
    "\n",
    "            X = X * self._idf_diag\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dd965b4c-db67-42fb-89f7-fef8450f7dc0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "angle\n",
      "express\n",
      "banquette\n",
      "\n",
      "ensemble | canapés | fauteuil\n",
      "clic | clac\n",
      "synthétique | 73 | 94 | siège | cuir\n",
      "bz | banquette | france\n",
      "angle\n",
      "méridienne | meridienne\n",
      "hauteur | clair | 69 | ab337299 | siège\n",
      "meridienne | 71872 | 829744 | 236x160x72 | poids\n",
      "microfibre | marron | 220 | doss | 69\n",
      "rotin | véritable | naturel | véranda | canapés\n",
      "rose | hauteur | 69 | épaisseur | siège\n",
      "microfibre | marron | vinyle | polychlorure | 69\n",
      "alma | 254 | 141 | 87 | 150\n",
      "220x92x90 | 44775 | 8216 | poids | kg\n",
      "meridienne | 284x166x70 | 697552 | 30008 | poids\n",
      "meridienne | poids | kg | total | volume\n",
      "microfibre | crème | ako7394667535542 | polychlorure | vinyle\n",
      "10256 | 252x220x74 | 550 | 738736 | meridienne\n",
      "fixe | siège | assemblage | partir | sol\n",
      "rouge | bordeaux | 117167 | a348967 | estink\n",
      "meridienne | poids | kg | total | volume\n",
      "278x220x74 | sovite | structurel | 100000 | constitué\n",
      "soulagent | continu | imposante | 270x125 | merveilleusement\n",
      "liy3080546 | 262 | dimensions | 35 | pied\n",
      "70 | 73 | siege | pcs | coussin\n",
      "creep | lità | créatio | renommée | retrouve\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# TFIDF VECTORIZER METHOD\n",
    "v = CustomClassTfidfTransformer(use_idf=True)\n",
    "x = v.fit_transform(vector)\n",
    "feature_array = np.array(vectorizer.get_feature_names_out())\n",
    "tfidf_sorting = np.argsort(x.toarray()).flatten()[::-1]\n",
    "top_words_per_cluster_tfidf = [get_top_tf_idf_words(item, 0.015, 5) for item in x]\n",
    "for top_words in top_words_per_cluster_tfidf:\n",
    "    print(top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d5bbd2ca-6cc4-412e-be0c-bfa5ecab13dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10731/10731 [07:43<00:00, 23.16it/s]\n",
      "100%|██████████| 31/31 [00:00<00:00, 302380.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results...\n",
      "/home/jupyter/Icarusight\n",
      "Results saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cluster_infos = get_cluster_labels(g, partitions)\n",
    "print(\"Saving results...\")\n",
    "save_results(\"results/results_threshold_at_0.015_cutoff_2.csv\", cluster_infos, top_words_per_cluster_count, top_words_per_cluster_tfidf)\n",
    "print(os.getcwd())\n",
    "print(\"Results saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (icarusight)",
   "language": "python",
   "name": "icarusight"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
